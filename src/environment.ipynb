{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0aade7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "sys.path.append(project_root)\n",
    "import habitat_sim\n",
    "import habitat\n",
    "from habitat.utils.visualizations import maps\n",
    "import numpy as np\n",
    "import cv2\n",
    "import imageio\n",
    "import os\n",
    "import yaml\n",
    "import torch\n",
    "from vint_train.utils import msg_to_pil, to_numpy, transform_images, load_model\n",
    "from diffusers.schedulers.scheduling_ddpm import DDPMScheduler\n",
    "from vint_train.training.train_utils import get_action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9678334f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- 1. 配置模拟器 (和你之前的代码类似) ---\n",
    "def make_sim_config(scene_path):\n",
    "    sim_cfg = habitat_sim.SimulatorConfiguration()\n",
    "    sim_cfg.scene_id = scene_path\n",
    "    sim_cfg.enable_physics = True\n",
    "    \n",
    "    agent_cfg = habitat_sim.agent.AgentConfiguration()\n",
    "    \n",
    "    # RGB 传感器\n",
    "    rgb_sensor = habitat_sim.CameraSensorSpec()\n",
    "    rgb_sensor.uuid = \"color_sensor\"\n",
    "    rgb_sensor.sensor_type = habitat_sim.SensorType.COLOR\n",
    "    rgb_sensor.resolution = [480, 640]\n",
    "    \n",
    "    agent_cfg.sensor_specifications = [rgb_sensor]\n",
    "    return habitat_sim.Configuration(sim_cfg, [agent_cfg])\n",
    "\n",
    "# --- 2. 辅助函数：绘制轨迹 ---\n",
    "def draw_trajectory(top_down_map, trajectory_points, color=(255, 0, 0)):\n",
    "    \"\"\"在地图上画线\"\"\"\n",
    "    if len(trajectory_points) < 2:\n",
    "        return top_down_map\n",
    "    \n",
    "    # 复制一份地图以免污染原图\n",
    "    map_with_traj = top_down_map.copy()\n",
    "    \n",
    "    # 将点连成线\n",
    "    for i in range(1, len(trajectory_points)):\n",
    "        pt1 = trajectory_points[i-1]\n",
    "        pt2 = trajectory_points[i]\n",
    "        cv2.line(map_with_traj, pt1, pt2, color, thickness=2)\n",
    "        \n",
    "    # 画当前位置（一个小圆圈）\n",
    "    cv2.circle(map_with_traj, trajectory_points[-1], 5, (0, 255, 0), -1)\n",
    "    return map_with_traj\n",
    "\n",
    "# --- 3. 主程序 ---\n",
    "# 替换为你的场景路径\n",
    "scene_path = \"/home/liuxh/vln/vint_docker_env/tmpdata/data/versioned_data/habitat_test_scenes/skokloster-castle.glb\"\n",
    "\n",
    "try:\n",
    "    cfg = make_sim_config(scene_path)\n",
    "    sim = habitat_sim.Simulator(cfg)\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    exit()\n",
    "\n",
    "# 初始化 Agent\n",
    "agent = sim.initialize_agent(0)\n",
    "\n",
    "# 获取一个随机的可行走点\n",
    "# max_tries=100 确保它尝试多次直到找到\n",
    "start_position = sim.pathfinder.get_random_navigable_point()\n",
    "\n",
    "# 设置给 Agent\n",
    "state = agent.get_state()\n",
    "state.position = start_position\n",
    "agent.set_state(state)\n",
    "\n",
    "# --- A. 预先生成静态地图 (只做一次) ---\n",
    "print(\"生成静态 Top-down 地图...\")\n",
    "# 获取当前高度，因为地图是基于高度切片的\n",
    "agent_height = agent.get_state().position[1]\n",
    "\n",
    "# meters_per_pixel 越小，地图越清晰，但生成越慢\n",
    "# 0.05 表示 1个像素代表 5cm\n",
    "top_down_map = maps.get_topdown_map(\n",
    "    sim.pathfinder, \n",
    "    height=agent_height, \n",
    "    meters_per_pixel=0.05\n",
    ")\n",
    "# 转换成彩色图片以便画红线 (原本是黑白的)\n",
    "top_down_map = maps.colorize_topdown_map(top_down_map)\n",
    "\n",
    "# 记录数据容器\n",
    "trajectory_grid_points = [] # 存储地图上的像素坐标 (x, y)\n",
    "video_frames = []\n",
    "total_steps = 1000\n",
    "\n",
    "print(\"开始录制...\")\n",
    "\n",
    "for step in range(total_steps):\n",
    "    # 1. 随机动作\n",
    "    action = np.random.choice([\"move_forward\", \"turn_left\", \"turn_right\"])\n",
    "    sim.step(action)\n",
    "    \n",
    "    # 2. 获取 RGB 图像\n",
    "    obs = sim.get_sensor_observations()\n",
    "    rgb_img = obs[\"color_sensor\"][..., :3] # 去掉 Alpha 通道\n",
    "    \n",
    "    # 3. 获取机器人真实位置\n",
    "    agent_state = agent.get_state()\n",
    "    position = agent_state.position\n",
    "    \n",
    "    # 4. 将 3D 世界坐标 转为 2D 地图像素坐标\n",
    "    # maps.to_grid 需要 (z, x) 顺序，因为 Habitat 坐标系 y 是向上\n",
    "    grid_loc = maps.to_grid(\n",
    "        realworld_x=position[2],\n",
    "        realworld_y=position[0],\n",
    "        grid_resolution=top_down_map.shape[0:2],\n",
    "        sim=sim\n",
    "    )\n",
    "    trajectory_grid_points.append([grid_loc[1],grid_loc[0]])\n",
    "    \n",
    "    # 5. 在地图上绘制轨迹\n",
    "    map_frame = draw_trajectory(top_down_map, trajectory_grid_points)\n",
    "    \n",
    "    # 6. 拼接图像 (Side-by-Side)\n",
    "    # 需要调整尺寸让它们高度一致\n",
    "    h_rgb, w_rgb = rgb_img.shape[:2]\n",
    "    h_map, w_map = map_frame.shape[:2]\n",
    "    \n",
    "    # 简单缩放地图以匹配 RGB 高度\n",
    "    scale = h_rgb / h_map\n",
    "    new_w_map = int(w_map * scale)\n",
    "    map_frame_resized = cv2.resize(map_frame, (new_w_map, h_rgb))\n",
    "    \n",
    "    # 拼在一起: [RGB] | [MAP]\n",
    "    combined_frame = np.hstack((rgb_img, map_frame_resized))\n",
    "    \n",
    "    video_frames.append(combined_frame)\n",
    "\n",
    "# --- 4. 保存视频 ---\n",
    "video_name = \"trajectory_vis.mp4\"\n",
    "print(f\"正在保存视频到 {video_name} ...\")\n",
    "imageio.mimsave(video_name, video_frames, fps=10)\n",
    "\n",
    "print(\"完成！\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63cb3d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "from ImageProvider import ImageProvider\n",
    "import Policy\n",
    "\n",
    "\n",
    "class Explorer:\n",
    "    def __init__(self, sim, policy, image_provider):\n",
    "        self.sim = sim\n",
    "        self.policy = policy\n",
    "        self.image_provider = image_provider\n",
    "\n",
    "    def step(self):\n",
    "        pass\n",
    "\n",
    "    def run(self):\n",
    "        pass\n",
    "\n",
    "    __call__ = run\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b3020d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('vint', {'config_path': '../../train/config/vint.yaml', 'ckpt_path': '../model_weights/vint.pth'}), ('late_fusion', {'config_path': '../../train/config/late_fusion.yaml', 'ckpt_path': '../model_weights/vint_late_fusion.pth'}), ('gnm', {'config_path': '../../train/config/gnm.yaml', 'ckpt_path': '../model_weights/gnm_large.pth'}), ('nomad', {'config_path': '/home/liuxh/vln/vint_docker_env/visualnav-transformer/deployment/config/models.yaml', 'ckpt_path': '/home/liuxh/vln/vint_docker_env/visualnav-transformer/deployment/model_weights/nomad.pth'})])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a21380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from /home/liuxh/vln/vint_docker_env/visualnav-transformer/deployment/model_weights/nomad.pth\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'rospy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 36\u001b[0m\n\u001b[1;32m     28\u001b[0m noise_scheduler \u001b[38;5;241m=\u001b[39m DDPMScheduler(\n\u001b[1;32m     29\u001b[0m     num_train_timesteps\u001b[38;5;241m=\u001b[39mmodel_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_diffusion_iters\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     30\u001b[0m     beta_schedule\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msquaredcos_cap_v2\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     31\u001b[0m     clip_sample\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     32\u001b[0m     prediction_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepsilon\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     33\u001b[0m )\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# ROS\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m \u001b[43mrospy\u001b[49m\u001b[38;5;241m.\u001b[39minit_node(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEXPLORATION\u001b[39m\u001b[38;5;124m\"\u001b[39m, anonymous\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     37\u001b[0m rate \u001b[38;5;241m=\u001b[39m rospy\u001b[38;5;241m.\u001b[39mRate(RATE)\n\u001b[1;32m     38\u001b[0m image_curr_msg \u001b[38;5;241m=\u001b[39m rospy\u001b[38;5;241m.\u001b[39mSubscriber(\n\u001b[1;32m     39\u001b[0m     IMAGE_TOPIC, Image, callback_obs, queue_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'rospy' is not defined"
     ]
    }
   ],
   "source": [
    "MODEL_CONFIG_PATH = \"/home/liuxh/vln/vint_docker_env/visualnav-transformer/deployment/config/models.yaml\"\n",
    "MODEL_WEIGHTS_PATH = \"/home/liuxh/vln/vint_docker_env/visualnav-transformer/deployment/model_weights/nomad.pth\"\n",
    "model_config_path = \"/home/liuxh/vln/vint_docker_env/visualnav-transformer/train/config/nomad.yaml\"\n",
    "device = 'cuda'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "with open(\"/home/liuxh/vln/vint_docker_env/visualnav-transformer/train/config/nomad.yaml\", \"r\") as f:\n",
    "    model_params = yaml.safe_load(f)\n",
    "\n",
    "context_size = model_params[\"context_size\"]\n",
    "\n",
    "# load model weights\n",
    "ckpth_path = MODEL_WEIGHTS_PATH\n",
    "if os.path.exists(ckpth_path):\n",
    "    print(f\"Loading model from {ckpth_path}\")\n",
    "else:\n",
    "    raise FileNotFoundError(f\"Model weights not found at {ckpth_path}\")\n",
    "model = load_model(\n",
    "    ckpth_path,\n",
    "    model_params,\n",
    ")\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "num_diffusion_iters = model_params[\"num_diffusion_iters\"]\n",
    "noise_scheduler = DDPMScheduler(\n",
    "    num_train_timesteps=model_params[\"num_diffusion_iters\"],\n",
    "    beta_schedule='squaredcos_cap_v2',\n",
    "    clip_sample=True,\n",
    "    prediction_type='epsilon'\n",
    ")\n",
    "\n",
    "# ROS\n",
    "rospy.init_node(\"EXPLORATION\", anonymous=False)\n",
    "rate = rospy.Rate(RATE)\n",
    "image_curr_msg = rospy.Subscriber(\n",
    "    IMAGE_TOPIC, Image, callback_obs, queue_size=1)\n",
    "waypoint_pub = rospy.Publisher(\n",
    "    WAYPOINT_TOPIC, Float32MultiArray, queue_size=1)  \n",
    "sampled_actions_pub = rospy.Publisher(SAMPLED_ACTIONS_TOPIC, Float32MultiArray, queue_size=1)\n",
    "\n",
    "print(\"Registered with master node. Waiting for image observations...\")\n",
    "\n",
    "while not rospy.is_shutdown():\n",
    "    # EXPLORATION MODE\n",
    "    waypoint_msg = Float32MultiArray()\n",
    "    if (\n",
    "            len(context_queue) > model_params[\"context_size\"]\n",
    "        ):\n",
    "\n",
    "        obs_images = transform_images(context_queue, model_params[\"image_size\"], center_crop=False)\n",
    "        obs_images = obs_images.to(device)\n",
    "        fake_goal = torch.randn((1, 3, *model_params[\"image_size\"])).to(device)\n",
    "        mask = torch.ones(1).long().to(device) # ignore the goal\n",
    "\n",
    "        # infer action\n",
    "        with torch.no_grad():\n",
    "            # encoder vision features\n",
    "            obs_cond = model('vision_encoder', obs_img=obs_images, goal_img=fake_goal, input_goal_mask=mask)\n",
    "            \n",
    "            # (B, obs_horizon * obs_dim)\n",
    "            if len(obs_cond.shape) == 2:\n",
    "                obs_cond = obs_cond.repeat(8, 1)\n",
    "            else:\n",
    "                obs_cond = obs_cond.repeat(8, 1, 1)\n",
    "            \n",
    "            # initialize action from Gaussian noise\n",
    "            noisy_action = torch.randn(\n",
    "                (8, model_params[\"len_traj_pred\"], 2), device=device)\n",
    "            naction = noisy_action\n",
    "\n",
    "            # init scheduler\n",
    "            noise_scheduler.set_timesteps(num_diffusion_iters)\n",
    "\n",
    "            start_time = time.time()\n",
    "            for k in noise_scheduler.timesteps[:]:\n",
    "                # predict noise\n",
    "                noise_pred = model(\n",
    "                    'noise_pred_net',\n",
    "                    sample=naction,\n",
    "                    timestep=k,\n",
    "                    global_cond=obs_cond\n",
    "                )\n",
    "\n",
    "                # inverse diffusion step (remove noise)\n",
    "                naction = noise_scheduler.step(\n",
    "                    model_output=noise_pred,\n",
    "                    timestep=k,\n",
    "                    sample=naction\n",
    "                ).prev_sample\n",
    "            print(\"time elapsed:\", time.time() - start_time)\n",
    "\n",
    "        naction = to_numpy(get_action(naction))\n",
    "        \n",
    "        sampled_actions_msg = Float32MultiArray()\n",
    "        sampled_actions_msg.data = np.concatenate((np.array([0]), naction.flatten()))\n",
    "        sampled_actions_pub.publish(sampled_actions_msg)\n",
    "\n",
    "        naction = naction[0] # change this based on heuristic\n",
    "\n",
    "        chosen_waypoint = naction[args.waypoint]\n",
    "\n",
    "        if model_params[\"normalize\"]:\n",
    "            chosen_waypoint *= (MAX_V / RATE)\n",
    "        waypoint_msg.data = chosen_waypoint\n",
    "        waypoint_pub.publish(waypoint_msg)\n",
    "        print(\"Published waypoint\")\n",
    "    rate.sleep()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "59fbd965",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DDPMScheduler {\n",
       "  \"_class_name\": \"DDPMScheduler\",\n",
       "  \"_diffusers_version\": \"0.35.2\",\n",
       "  \"beta_end\": 0.02,\n",
       "  \"beta_schedule\": \"squaredcos_cap_v2\",\n",
       "  \"beta_start\": 0.0001,\n",
       "  \"clip_sample\": true,\n",
       "  \"clip_sample_range\": 1.0,\n",
       "  \"dynamic_thresholding_ratio\": 0.995,\n",
       "  \"num_train_timesteps\": 10,\n",
       "  \"prediction_type\": \"epsilon\",\n",
       "  \"rescale_betas_zero_snr\": false,\n",
       "  \"sample_max_value\": 1.0,\n",
       "  \"steps_offset\": 0,\n",
       "  \"thresholding\": false,\n",
       "  \"timestep_spacing\": \"leading\",\n",
       "  \"trained_betas\": null,\n",
       "  \"variance_type\": \"fixed_small\"\n",
       "}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noise_scheduler"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "habitat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
